{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9694ad9b-a54f-45a2-b17c-6a8e0620392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# import torch\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19621729-7879-4fcf-b348-849865cbd399",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-llms-openai 0.1.31 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.10.28 which is incompatible.\n",
      "llama-index-program-openai 0.1.7 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.10.28 which is incompatible.\n",
      "llama-index-readers-file 0.1.33 requires llama-index-core<0.11.0,>=0.10.37.post1, but you have llama-index-core 0.10.28 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-program-openai 0.1.7 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.10.28 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Found existing installation: transformers 4.51.2\n",
      "Uninstalling transformers-4.51.2:\n",
      "  Successfully uninstalled transformers-4.51.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting transformers==4.36.2\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.2)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (2022.12.7)\n",
      "Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.1\n",
      "    Uninstalling tokenizers-0.21.1:\n",
      "      Successfully uninstalled tokenizers-0.21.1\n",
      "Successfully installed tokenizers-0.15.2 transformers-4.36.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q numpy==1.26.4\n",
    "# !pip install -q datasets huggingface-hub\n",
    "# !pip install -q llama-index llama-index-core llama-index-llms-openai openai llama-index-postprocessor-longllmlingua\n",
    "!pip install -q accelerate==0.29.2\n",
    "!pip install -q datasets==2.18.0\n",
    "!pip install -q llama-index==0.10.7\n",
    "!pip install -q llama-index-agent-openai==0.1.7\n",
    "!pip install -q llama-index-core==0.10.28\n",
    "!pip install -q llama-index-embeddings-openai==0.1.7\n",
    "!pip install -q llama-index-legacy==0.9.48\n",
    "!pip install -q llama-index-llms-openai==0.1.15\n",
    "!pip install -q llama-index-multi-modal-llms-openai==0.1.5\n",
    "!pip install -q llama-index-postprocessor-longllmlingua==0.1.2\n",
    "!pip install -q llama-index-program-openai==0.1.5\n",
    "!pip install -q llama-index-question-gen-openai==0.1.3\n",
    "!pip install -q llama-index-readers-file==0.1.16\n",
    "!pip install -q llamaindex-py-client==0.1.18\n",
    "!pip install -q llmlingua==0.2.2\n",
    "!pip uninstall transformers -y\n",
    "!pip install transformers==4.36.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f037ee52-20ef-49b9-9343-ec559368305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "import openai\n",
    "from llama_index.core import Document\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.indices.query.schema import QueryBundle\n",
    "from llama_index.core.response_synthesizers import CompactAndRefine\n",
    "from llama_index.postprocessor.longllmlingua import LongLLMLinguaPostprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8437e04c-8ba9-4a90-b45d-cd35d805131c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b7011a05984ee58201790f00d4f9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c738f0774de479681378a27659d1d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9db6115ac343b6b9eb96c22834a198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3cf5f4f9814165b617b9caa73e1673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6a1b15b9d645cd954fd0ab5f71373e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73b2d9f16c345c4aef8ac36b2a60d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649c76ce091849ab8d7513a1f10018a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae327bbf27c40a3897dc0eb29c37bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb233ce7ea44cfebdbc3dd25d7ff601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf0eeb6c1024b7d813ecb3a1cadb87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712d369dc6864c9aa15a3f42a8cf0b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 비압축 RAG에서 사용할 프롬프트 모델 유형을 설정합니다.\n",
    "# (압축 RAG의 프롬프트 모델은 기본값으로 \"gpt-4o-mini\"로 설정되어 있으며,\n",
    "# 압축 모델은 기본값으로 \"NousResearch/Llama-2-7b-hf\"로 설정됩니다.)\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "\n",
    "# 실행할 실험 횟수입니다. 각 실험은 사용자가 특정 Arxiv 출판물에 대해 질문을 하는 RAG 작업을 나타냅니다.\n",
    "num_of_iterations = 5\n",
    "\n",
    "# 각 실험에서 Arxiv 출판물은 랜덤하게 선택되므로, 원래 결과의 재현성을 보장하기 위해 고정된 시드를 설정합니다.\n",
    "set_seed = 0\n",
    "\n",
    "# 각 실험에서 RAG가 검색할 유사한 청크의 개수입니다.\n",
    "similarity_top_k = 5\n",
    "\n",
    "# 검색된 문맥을 압축할 때 목표로 하는 토큰 수입니다.\n",
    "target_token = 2**9\n",
    "\n",
    "# OpenAI의 LLM 초기화\n",
    "llm = OpenAI(model=gpt_model)\n",
    "\n",
    "# LongLLMLinguaPostprocessor 초기화\n",
    "postprocessor = LongLLMLinguaPostprocessor(\n",
    "    model_name=\"NousResearch/Llama-2-7b-hf\",  # ✅ LLaMA2 계열로 교체, 안정적\n",
    "    # model_name = \"beomi/open-llama-2-ko-7b\", # 한국어 모델도 가능\n",
    "    target_token=target_token,\n",
    "    rank_method=\"longllmlingua\",\n",
    "    additional_compress_kwargs={\n",
    "        \"condition_compare\": True,\n",
    "        \"condition_in_question\": \"after\",\n",
    "        \"context_budget\": \"+100\",\n",
    "        \"reorder_context\": \"sort\",\n",
    "        \"dynamic_context_compression_ratio\": 0.3,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "202c171d-1fa2-4281-aa40-e600bb73ea89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38586155ca5e4aad924c796330166e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/3.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 218M/218M [00:00<00:00, 346MB/s] \n",
      "Downloading data: 100%|██████████| 215M/215M [00:00<00:00, 268MB/s]  \n",
      "Downloading data: 100%|██████████| 215M/215M [00:00<00:00, 295MB/s] \n",
      "Downloading data: 100%|██████████| 214M/214M [00:00<00:00, 238MB/s]  \n",
      "Downloading data: 100%|██████████| 75.4M/75.4M [00:00<00:00, 197MB/s] \n",
      "Downloading data: 100%|██████████| 74.0M/74.0M [00:00<00:00, 168MB/s] \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517b16c0de2049a3853043c177fcd9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/28388 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cd910f19bf43099d6213e7ac2aa6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320dc7c57c3e49eab4e62a6e05c9c10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ccdv/arxiv-classification\")\n",
    "dataset_train = dataset[\"train\"]\n",
    "dataset_train_df = pd.DataFrame(dataset_train)\n",
    "\n",
    "# AI 관련 논문만 유지 (라벨이 #2로 분류된 것만 필터링):\n",
    "dataset_train_df_ai = dataset_train_df[dataset_train_df[\"label\"] == 2].reset_index(drop=True)\n",
    "\n",
    "articles = [Document(text=content) for content in dataset_train_df_ai[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "990391fb-fb0a-4677-ac34-7880ee05fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Does this publication involve Reinforcement Learning? Answer in a single word, either Yes or No\"\n",
    "# query = \"이 출판물이 강화 학습(Reinforcement Learning)과 관련이 있나요? 단어 하나로 대답하세요, Yes 또는 No 중 하나로.\"\n",
    "\n",
    "# 결과를 기록할 딕셔너리 설정:\n",
    "# 두 가지 분류 RAG 간의 일치 여부와 추적 중인 메트릭을 저장:\n",
    "record = {\n",
    "    \"Yes,Yes\": 0,  # 두 방식 모두 긍정\n",
    "    \"No,No\": 0,    # 두 방식 모두 부정\n",
    "    \"Yes,No\": 0,   # 비압축 방식 긍정, 압축 방식 부정\n",
    "    \"No,Yes\": 0,   # 비압축 방식 부정, 압축 방식 긍정\n",
    "    \"original_tokens\": [],  # 원래 문맥의 토큰 수\n",
    "    \"compressed_tokens\": [],  # 압축된 문맥의 토큰 수\n",
    "    \"ratios\": [],  # 압축 비율\n",
    "    \"time_nc\": [],  # 비압축 방식의 실행 시간\n",
    "    \"time_c\": [],   # 압축 방식의 실행 시간\n",
    "}\n",
    "\n",
    "# GPU의 불필요한 캐시 공간을 정리하는 것은 좋은 습관입니다:\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 모든 문서를 반복하지 않기 위해 랜덤하게 문서를 선택합니다:\n",
    "random.seed(set_seed)\n",
    "random_iterations = random.sample(range(len(articles)), num_of_iterations)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(articles[1:2])\n",
    "\n",
    "# 벡터 DB에서 top_k 청크 검색:\n",
    "retriever = index.as_retriever(similarity_top_k=similarity_top_k)\n",
    "retrieved_context = retriever.retrieve(query)\n",
    "context_list = [chunk.get_content() for chunk in retrieved_context]\n",
    "\n",
    "# 압축된 문맥으로 LLM에 프롬프트 전달:\n",
    "new_retrieved_context = postprocessor.postprocess_nodes(\n",
    "    retrieved_context,\n",
    "    query_bundle=QueryBundle(query_str=query)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0948c4e9-e1b0-4aae-97af-61230a87a115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "📌 [압축 전 문맥]\n",
      "Advances in Neural Information Processing Systems 30, NIPS, 2017. 3\n",
      "[22] K. Fragkiadaki, P. Agrawal, S. Levine, and J. Malik. Learning visual predictive models of physics for playing billiards.\n",
      "ICLR, 2016. 4, 7\n",
      "[23] H. Gao, J. Mao, J. Zhou, Z. Huang, L. Wang, and W. Xu.\n",
      "Are you talking to a machine? dataset and methods for multilingual image question. In Advances in Neural Information\n",
      "Processing Systems, pages 2296–2304, 2015. 3\n",
      "[24] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu,\n",
      "D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In Advances in neural information\n",
      "processing systems, pages 2672–2680, 2014. 7\n",
      "[25] J. B. Hamrick, R. Pascanu, O. Vinyals, A. Ballard, N. Heess,\n",
      "and P. Battaglia. Imagination-based decision making with\n",
      "physical models in deep neural networks. 4\n",
      "[26] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE Con-\n",
      "\n",
      "\f",
      "[27]\n",
      "\n",
      "[28]\n",
      "\n",
      "[29]\n",
      "\n",
      "[30]\n",
      "[31]\n",
      "\n",
      "[32]\n",
      "\n",
      "[33]\n",
      "\n",
      "[34]\n",
      "\n",
      "[35]\n",
      "\n",
      "[36]\n",
      "[37]\n",
      "\n",
      "[38]\n",
      "\n",
      "[39]\n",
      "\n",
      "[40]\n",
      "\n",
      "[41]\n",
      "\n",
      "[42]\n",
      "\n",
      "ference on Computer Vision and Pattern Recognition, pages\n",
      "770–778, 2016. 1, 3, 7\n",
      "Y. Jiang, J. Liu, A. R. Zamir, G. Toderici, I. Laptev, M. Shah,\n",
      "and R. Sukthankar. Thumos challenge: Action recognition\n",
      "with a large number of classes, 2014. 2\n",
      "J. Johnson, B. Hariharan, L. van der Maaten, L. Fei-Fei,\n",
      "C. L. Zitnick, and R. Girshick. Clevr: A diagnostic dataset\n",
      "for compositional language and elementary visual reasoning.\n",
      "arXiv preprint arXiv:1612.06890, 2016. 2, 3\n",
      "P. J. Kellman and E. S. Spelke. Perception of partly occluded\n",
      "objects in infancy. Cognitive psychology, 15(4):483–524,\n",
      "1983. 1\n",
      "D. P. Kingma and J. Ba. Adam: A method for stochastic\n",
      "optimization. CoRR, abs/1412.6980, 2014. 12\n",
      "R. Krishna, Y. Zhu, O. Groth, J. Johnson, K. Hata, J. Kravitz,\n",
      "S. Chen, Y. Kalantidis, L.-J. Li, D. A. Shamma, et al. Visual genome: Connecting language and vision using crowdsourced dense image annotations. International Journal of\n",
      "Computer Vision, 123(1):32–73, 2017. 3\n",
      "M. Kristan, A. Leonardis, J. Matas, M. Felsberg,\n",
      "R. Pflugfelder, L. Čehovin, T. Vojir, G. Häger, A. Lukežič,\n",
      "and G. Fernandez. The visual object tracking vot2016 challenge results. Springer, Oct 2016. 3\n",
      "A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet\n",
      "classification with deep convolutional neural networks. In\n",
      "F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger,\n",
      "editors, Advances in Neural Information Processing Systems\n",
      "25, pages 1097–1105. Curran Associates, Inc., 2012. 1, 3\n",
      "L. Leal-Taixé, A. Milan, I. Reid, S. Roth, and K. Schindler.\n",
      "MOTChallenge 2015: Towards a benchmark for multitarget tracking. arXiv:1504.01942 [cs], Apr. 2015. arXiv:\n",
      "1504.01942. 3\n",
      "A. Lerer, S. Gross, and R. Fergus. Learning physical intuition of block towers by example. International Conference\n",
      "on Machine Learning (ICML), 2016.\n",
      "\n",
      "IntPhys: A Framework and Benchmark for Visual Intuitive Physics Reasoning\n",
      "Ronan Riochet\n",
      "Ecole Normale Superieure\n",
      "INRIA\n",
      "\n",
      "Mario Ynocente Castro\n",
      "ycmario@gmail.com\n",
      "\n",
      "arXiv:1803.07\n",
      "\n",
      "🔢 토큰 수 (압축 전): 5665\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "📌 [압축 후 문맥]\n",
      "1. Introduction\n",
      "Despite impressive progress in machine vision on many\n",
      "tasks (face recognition [68], object recognition [33], [26],\n",
      "object segmentation [52], etc.), artificial systems are still far\n",
      "from human-level understanding of complex scenes. Scene\n",
      "understanding involves not only segmenting and tracking\n",
      "of objects across time, but also representing the spatial and\n",
      "temporal relationships between these objects and being able\n",
      "1\n",
      "\n",
      "\f",
      "Supplementary Material\n",
      " Framework details\n",
      "2 Rel work\n",
      "Most of the for intuitive\n",
      "has been conducted in the context particular end-to-endapplications. distinguish three broad classes depending on the type of data they use. The first\n",
      "includes tasks the vision- interface, where a\n",
      "model’s ability to reason about an image is assessed through\n",
      "a language task (e.g. generating a caption or answering a\n",
      "question about the image). The second class includes tasks\n",
      "which only use images or videos as input, such as predicting events in a video or tracking objects through time.\n",
      "The third class involves vision-action interface, with applications in robotics. that case systems require reasoning to control actions and predict their outcome.\n",
      "\n",
      "arXiv1803.7616v1 [cs.AI] 20 Mar 2018\n",
      "Adam\n",
      "Facebook AI Research\n",
      "Rob Fergus\n",
      "Facebook AI Research\n",
      "\n",
      "9. D\n",
      "See ,45 for’ architect,Figure 6 samples semantic mask.\n",
      " https://github./\n",
      "rIntPhys-Baselines\n",
      "Abstract\n",
      "\n",
      "] Rhang, J, C Z, W. T, J. B. Tenenbaum A compar evaluation of simulation neural networks accounts human. CS,1.75]. Litnick and D. Parikh. Bring semanticsceedings of Conferenceisionognition30936, 03. \n",
      "\n",
      ". TrainingIntPhys: andchmark Visual Intuitive Physics\n",
      "on Riochcoleure\n",
      "INA\n",
      "an.et@.fr\n",
      "\n",
      "[10] G. Brockman, V. Cheung, L. Pettersson, J. Schneider,\n",
      "J. Schulman, J. Tang, and W. Zaremba. Openai gym. CoRR,\n",
      "abs/1606.01540, 2016. 2\n",
      "[11] S. Carey. The origin of concepts. Oxford series in cognitive\n",
      "development. Oxford University Press, Oxford ; New York,\n",
      "2009.\n",
      "\n",
      "🔢 토큰 수 (압축 후): 554\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 압축 전 원본 문맥 출력\n",
    "original_contexts = \"\\n\\n\".join([chunk.get_content() for chunk in retrieved_context])\n",
    "original_tokens = postprocessor._llm_lingua.get_token_length(original_contexts)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"📌 [압축 전 문맥]\")\n",
    "print(original_contexts[:3000])  # 너무 길면 앞 부분만 미리 확인\n",
    "print(f\"\\n🔢 토큰 수 (압축 전): {original_tokens}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 압축 후 문맥 출력\n",
    "compressed_contexts = \"\\n\\n\".join([chunk.get_content() for chunk in new_retrieved_context])\n",
    "compressed_tokens = postprocessor._llm_lingua.get_token_length(compressed_contexts)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📌 [압축 후 문맥]\")\n",
    "print(compressed_contexts[:3000])  # 마찬가지로 앞부분만 출력\n",
    "print(f\"\\n🔢 토큰 수 (압축 후): {compressed_tokens}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d8504-2ca6-49a5-816b-ca461253a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문서에 대해 독립적인 실험을 진행\n",
    "for document_index in random_iterations:\n",
    "    # 검색을 위해 관련 문서만 참조하고 이를 벡터 데이터베이스로 처리:\n",
    "    index = VectorStoreIndex.from_documents(articles[document_index:(document_index + 1)])\n",
    "    print(\"\\n\\n                                                 문서 인덱스:\", document_index)\n",
    "    print(\"                                                 반복 횟수:\", iteration_counter, \"/\", num_of_iterations)\n",
    "    iteration_counter += 1\n",
    "\n",
    "    # RAG 검색: 이 부분은 비압축 및 압축 방식 모두에서 공통:\n",
    "    retrieval_start_time = time.time()\n",
    "    # 벡터 DB에서 top_k 청크 검색:\n",
    "    retriever = index.as_retriever(similarity_top_k=similarity_top_k)\n",
    "    retrieved_context = retriever.retrieve(query)\n",
    "    context_list = [chunk.get_content() for chunk in retrieved_context]\n",
    "    retrieval_time = time.time() - retrieval_start_time\n",
    "\n",
    "    # 비압축 RAG 방식:\n",
    "    # 압축 없이 LLM에 프롬프트를 전달하며, 쿼리에 검색된 문맥 청크를 추가:\n",
    "    start_time_nc = time.time()\n",
    "    prompt = \"\\n\\n\".join(context_list + [query])\n",
    "    response_nc = llm.complete(prompt)\n",
    "    time_nc = time.time() - start_time_nc\n",
    "    print(\"------------------------------------------------ 비압축 방식 응답: \" + str(response_nc))\n",
    "\n",
    "    original_contexts = \"\\n\\n\".join(context_list)\n",
    "    original_tokens = postprocessor._llm_lingua.get_token_length(original_contexts)\n",
    "\n",
    "    # 이 시점에서 GPU 메모리를 정리하는 것이 필요합니다:\n",
    "    del prompt\n",
    "    del context_list\n",
    "    del original_contexts\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # 압축 문맥 RAG 방식:\n",
    "    # 압축된 문맥으로 LLM에 프롬프트 전달:\n",
    "    start_time_c = time.time()\n",
    "    new_retrieved_context = postprocessor.postprocess_nodes(\n",
    "        retrieved_context,\n",
    "        query_bundle=QueryBundle(query_str=query)\n",
    "    )\n",
    "\n",
    "    response_c = CompactAndRefine().synthesize(query, new_retrieved_context)\n",
    "\n",
    "    time_c = time.time() - start_time_c\n",
    "\n",
    "    print(\"------------------------------------------------ 압축 방식 응답: \" + str(response_c))\n",
    "\n",
    "    compressed_contexts = \"\\n\\n\".join([chunk.get_content() for chunk in new_retrieved_context])\n",
    "\n",
    "    compressed_tokens = postprocessor._llm_lingua.get_token_length(compressed_contexts)\n",
    "    ratio = original_tokens / (compressed_tokens + 1)\n",
    "\n",
    "    print(\"원래 토큰 수:\", original_tokens)\n",
    "    print(\"압축된 토큰 수:\", compressed_tokens)\n",
    "    print(\"압축 비율:\", f\"{ratio:.2f}배\")\n",
    "\n",
    "    record[str(response_nc).replace(\".\", \"\") + \",\" + str(response_c).replace(\".\", \"\")] += 1\n",
    "    record[\"original_tokens\"].append(original_tokens)\n",
    "    record[\"compressed_tokens\"].append(compressed_tokens)\n",
    "    record[\"ratios\"].append(ratio)\n",
    "    record[\"time_nc\"].append(time_nc + retrieval_time)\n",
    "    record[\"time_c\"].append(time_c + retrieval_time)\n",
    "\n",
    "    # GPU의 불필요한 캐시 공간을 정리하는 것은 좋은 습관입니다:\n",
    "    del compressed_contexts\n",
    "    del new_retrieved_context\n",
    "    del retrieved_context\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c60914-3a66-4c34-ba22-2a395ee68781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0426f5-118a-4025-abc2-402c5b5afead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8901841d-73e1-4ca8-ac0c-853cf0c98843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
