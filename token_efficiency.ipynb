{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9694ad9b-a54f-45a2-b17c-6a8e0620392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# import torch\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19621729-7879-4fcf-b348-849865cbd399",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-llms-openai 0.1.31 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.10.28 which is incompatible.\n",
      "llama-index-program-openai 0.1.7 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.10.28 which is incompatible.\n",
      "llama-index-readers-file 0.1.33 requires llama-index-core<0.11.0,>=0.10.37.post1, but you have llama-index-core 0.10.28 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-program-openai 0.1.7 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.10.28 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Found existing installation: transformers 4.51.2\n",
      "Uninstalling transformers-4.51.2:\n",
      "  Successfully uninstalled transformers-4.51.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting transformers==4.36.2\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.2)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (2022.12.7)\n",
      "Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.1\n",
      "    Uninstalling tokenizers-0.21.1:\n",
      "      Successfully uninstalled tokenizers-0.21.1\n",
      "Successfully installed tokenizers-0.15.2 transformers-4.36.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q numpy==1.26.4\n",
    "# !pip install -q datasets huggingface-hub\n",
    "# !pip install -q llama-index llama-index-core llama-index-llms-openai openai llama-index-postprocessor-longllmlingua\n",
    "!pip install -q accelerate==0.29.2\n",
    "!pip install -q datasets==2.18.0\n",
    "!pip install -q llama-index==0.10.7\n",
    "!pip install -q llama-index-agent-openai==0.1.7\n",
    "!pip install -q llama-index-core==0.10.28\n",
    "!pip install -q llama-index-embeddings-openai==0.1.7\n",
    "!pip install -q llama-index-legacy==0.9.48\n",
    "!pip install -q llama-index-llms-openai==0.1.15\n",
    "!pip install -q llama-index-multi-modal-llms-openai==0.1.5\n",
    "!pip install -q llama-index-postprocessor-longllmlingua==0.1.2\n",
    "!pip install -q llama-index-program-openai==0.1.5\n",
    "!pip install -q llama-index-question-gen-openai==0.1.3\n",
    "!pip install -q llama-index-readers-file==0.1.16\n",
    "!pip install -q llamaindex-py-client==0.1.18\n",
    "!pip install -q llmlingua==0.2.2\n",
    "!pip uninstall transformers -y\n",
    "!pip install transformers==4.36.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f037ee52-20ef-49b9-9343-ec559368305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "import openai\n",
    "from llama_index.core import Document\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.indices.query.schema import QueryBundle\n",
    "from llama_index.core.response_synthesizers import CompactAndRefine\n",
    "from llama_index.postprocessor.longllmlingua import LongLLMLinguaPostprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8437e04c-8ba9-4a90-b45d-cd35d805131c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b7011a05984ee58201790f00d4f9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c738f0774de479681378a27659d1d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9db6115ac343b6b9eb96c22834a198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3cf5f4f9814165b617b9caa73e1673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6a1b15b9d645cd954fd0ab5f71373e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73b2d9f16c345c4aef8ac36b2a60d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649c76ce091849ab8d7513a1f10018a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae327bbf27c40a3897dc0eb29c37bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb233ce7ea44cfebdbc3dd25d7ff601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf0eeb6c1024b7d813ecb3a1cadb87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712d369dc6864c9aa15a3f42a8cf0b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ÎπÑÏïïÏ∂ï RAGÏóêÏÑú ÏÇ¨Ïö©Ìï† ÌîÑÎ°¨ÌîÑÌä∏ Î™®Îç∏ Ïú†ÌòïÏùÑ ÏÑ§Ï†ïÌï©ÎãàÎã§.\n",
    "# (ÏïïÏ∂ï RAGÏùò ÌîÑÎ°¨ÌîÑÌä∏ Î™®Îç∏ÏùÄ Í∏∞Î≥∏Í∞íÏúºÎ°ú \"gpt-4o-mini\"Î°ú ÏÑ§Ï†ïÎêòÏñ¥ ÏûàÏúºÎ©∞,\n",
    "# ÏïïÏ∂ï Î™®Îç∏ÏùÄ Í∏∞Î≥∏Í∞íÏúºÎ°ú \"NousResearch/Llama-2-7b-hf\"Î°ú ÏÑ§Ï†ïÎê©ÎãàÎã§.)\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "\n",
    "# Ïã§ÌñâÌï† Ïã§Ìóò ÌöüÏàòÏûÖÎãàÎã§. Í∞Å Ïã§ÌóòÏùÄ ÏÇ¨Ïö©ÏûêÍ∞Ä ÌäπÏ†ï Arxiv Ï∂úÌåêÎ¨ºÏóê ÎåÄÌï¥ ÏßàÎ¨∏ÏùÑ ÌïòÎäî RAG ÏûëÏóÖÏùÑ ÎÇòÌÉÄÎÉÖÎãàÎã§.\n",
    "num_of_iterations = 5\n",
    "\n",
    "# Í∞Å Ïã§ÌóòÏóêÏÑú Arxiv Ï∂úÌåêÎ¨ºÏùÄ ÎûúÎç§ÌïòÍ≤å ÏÑ†ÌÉùÎêòÎØÄÎ°ú, ÏõêÎûò Í≤∞Í≥ºÏùò Ïû¨ÌòÑÏÑ±ÏùÑ Î≥¥Ïû•ÌïòÍ∏∞ ÏúÑÌï¥ Í≥†Ï†ïÎêú ÏãúÎìúÎ•º ÏÑ§Ï†ïÌï©ÎãàÎã§.\n",
    "set_seed = 0\n",
    "\n",
    "# Í∞Å Ïã§ÌóòÏóêÏÑú RAGÍ∞Ä Í≤ÄÏÉâÌï† Ïú†ÏÇ¨Ìïú Ï≤≠ÌÅ¨Ïùò Í∞úÏàòÏûÖÎãàÎã§.\n",
    "similarity_top_k = 5\n",
    "\n",
    "# Í≤ÄÏÉâÎêú Î¨∏Îß•ÏùÑ ÏïïÏ∂ïÌï† Îïå Î™©ÌëúÎ°ú ÌïòÎäî ÌÜ†ÌÅ∞ ÏàòÏûÖÎãàÎã§.\n",
    "target_token = 2**9\n",
    "\n",
    "# OpenAIÏùò LLM Ï¥àÍ∏∞Ìôî\n",
    "llm = OpenAI(model=gpt_model)\n",
    "\n",
    "# LongLLMLinguaPostprocessor Ï¥àÍ∏∞Ìôî\n",
    "postprocessor = LongLLMLinguaPostprocessor(\n",
    "    model_name=\"NousResearch/Llama-2-7b-hf\",  # ‚úÖ LLaMA2 Í≥ÑÏó¥Î°ú ÍµêÏ≤¥, ÏïàÏ†ïÏ†Å\n",
    "    # model_name = \"beomi/open-llama-2-ko-7b\", # ÌïúÍµ≠Ïñ¥ Î™®Îç∏ÎèÑ Í∞ÄÎä•\n",
    "    target_token=target_token,\n",
    "    rank_method=\"longllmlingua\",\n",
    "    additional_compress_kwargs={\n",
    "        \"condition_compare\": True,\n",
    "        \"condition_in_question\": \"after\",\n",
    "        \"context_budget\": \"+100\",\n",
    "        \"reorder_context\": \"sort\",\n",
    "        \"dynamic_context_compression_ratio\": 0.3,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "202c171d-1fa2-4281-aa40-e600bb73ea89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38586155ca5e4aad924c796330166e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/3.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 218M/218M [00:00<00:00, 346MB/s] \n",
      "Downloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215M/215M [00:00<00:00, 268MB/s]  \n",
      "Downloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215M/215M [00:00<00:00, 295MB/s] \n",
      "Downloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 214M/214M [00:00<00:00, 238MB/s]  \n",
      "Downloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75.4M/75.4M [00:00<00:00, 197MB/s] \n",
      "Downloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74.0M/74.0M [00:00<00:00, 168MB/s] \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517b16c0de2049a3853043c177fcd9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/28388 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cd910f19bf43099d6213e7ac2aa6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320dc7c57c3e49eab4e62a6e05c9c10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ccdv/arxiv-classification\")\n",
    "dataset_train = dataset[\"train\"]\n",
    "dataset_train_df = pd.DataFrame(dataset_train)\n",
    "\n",
    "# AI Í¥ÄÎ†® ÎÖºÎ¨∏Îßå Ïú†ÏßÄ (ÎùºÎ≤®Ïù¥ #2Î°ú Î∂ÑÎ•òÎêú Í≤ÉÎßå ÌïÑÌÑ∞ÎßÅ):\n",
    "dataset_train_df_ai = dataset_train_df[dataset_train_df[\"label\"] == 2].reset_index(drop=True)\n",
    "\n",
    "articles = [Document(text=content) for content in dataset_train_df_ai[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "990391fb-fb0a-4677-ac34-7880ee05fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Does this publication involve Reinforcement Learning? Answer in a single word, either Yes or No\"\n",
    "# query = \"Ïù¥ Ï∂úÌåêÎ¨ºÏù¥ Í∞ïÌôî ÌïôÏäµ(Reinforcement Learning)Í≥º Í¥ÄÎ†®Ïù¥ ÏûàÎÇòÏöî? Îã®Ïñ¥ ÌïòÎÇòÎ°ú ÎåÄÎãµÌïòÏÑ∏Ïöî, Yes ÎòêÎäî No Ï§ë ÌïòÎÇòÎ°ú.\"\n",
    "\n",
    "# Í≤∞Í≥ºÎ•º Í∏∞Î°ùÌï† ÎîïÏÖîÎÑàÎ¶¨ ÏÑ§Ï†ï:\n",
    "# Îëê Í∞ÄÏßÄ Î∂ÑÎ•ò RAG Í∞ÑÏùò ÏùºÏπò Ïó¨Î∂ÄÏôÄ Ï∂îÏ†Å Ï§ëÏù∏ Î©îÌä∏Î¶≠ÏùÑ Ï†ÄÏû•:\n",
    "record = {\n",
    "    \"Yes,Yes\": 0,  # Îëê Î∞©Ïãù Î™®Îëê Í∏çÏ†ï\n",
    "    \"No,No\": 0,    # Îëê Î∞©Ïãù Î™®Îëê Î∂ÄÏ†ï\n",
    "    \"Yes,No\": 0,   # ÎπÑÏïïÏ∂ï Î∞©Ïãù Í∏çÏ†ï, ÏïïÏ∂ï Î∞©Ïãù Î∂ÄÏ†ï\n",
    "    \"No,Yes\": 0,   # ÎπÑÏïïÏ∂ï Î∞©Ïãù Î∂ÄÏ†ï, ÏïïÏ∂ï Î∞©Ïãù Í∏çÏ†ï\n",
    "    \"original_tokens\": [],  # ÏõêÎûò Î¨∏Îß•Ïùò ÌÜ†ÌÅ∞ Ïàò\n",
    "    \"compressed_tokens\": [],  # ÏïïÏ∂ïÎêú Î¨∏Îß•Ïùò ÌÜ†ÌÅ∞ Ïàò\n",
    "    \"ratios\": [],  # ÏïïÏ∂ï ÎπÑÏú®\n",
    "    \"time_nc\": [],  # ÎπÑÏïïÏ∂ï Î∞©ÏãùÏùò Ïã§Ìñâ ÏãúÍ∞Ñ\n",
    "    \"time_c\": [],   # ÏïïÏ∂ï Î∞©ÏãùÏùò Ïã§Ìñâ ÏãúÍ∞Ñ\n",
    "}\n",
    "\n",
    "# GPUÏùò Î∂àÌïÑÏöîÌïú Ï∫êÏãú Í≥µÍ∞ÑÏùÑ Ï†ïÎ¶¨ÌïòÎäî Í≤ÉÏùÄ Ï¢ãÏùÄ ÏäµÍ¥ÄÏûÖÎãàÎã§:\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Î™®Îì† Î¨∏ÏÑúÎ•º Î∞òÎ≥µÌïòÏßÄ ÏïäÍ∏∞ ÏúÑÌï¥ ÎûúÎç§ÌïòÍ≤å Î¨∏ÏÑúÎ•º ÏÑ†ÌÉùÌï©ÎãàÎã§:\n",
    "random.seed(set_seed)\n",
    "random_iterations = random.sample(range(len(articles)), num_of_iterations)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(articles[1:2])\n",
    "\n",
    "# Î≤°ÌÑ∞ DBÏóêÏÑú top_k Ï≤≠ÌÅ¨ Í≤ÄÏÉâ:\n",
    "retriever = index.as_retriever(similarity_top_k=similarity_top_k)\n",
    "retrieved_context = retriever.retrieve(query)\n",
    "context_list = [chunk.get_content() for chunk in retrieved_context]\n",
    "\n",
    "# ÏïïÏ∂ïÎêú Î¨∏Îß•ÏúºÎ°ú LLMÏóê ÌîÑÎ°¨ÌîÑÌä∏ Ï†ÑÎã¨:\n",
    "new_retrieved_context = postprocessor.postprocess_nodes(\n",
    "    retrieved_context,\n",
    "    query_bundle=QueryBundle(query_str=query)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0948c4e9-e1b0-4aae-97af-61230a87a115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìå [ÏïïÏ∂ï Ï†Ñ Î¨∏Îß•]\n",
      "Advances in Neural Information Processing Systems 30, NIPS, 2017. 3\n",
      "[22] K. Fragkiadaki, P. Agrawal, S. Levine, and J. Malik. Learning visual predictive models of physics for playing billiards.\n",
      "ICLR, 2016. 4, 7\n",
      "[23] H. Gao, J. Mao, J. Zhou, Z. Huang, L. Wang, and W. Xu.\n",
      "Are you talking to a machine? dataset and methods for multilingual image question. In Advances in Neural Information\n",
      "Processing Systems, pages 2296‚Äì2304, 2015. 3\n",
      "[24] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu,\n",
      "D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In Advances in neural information\n",
      "processing systems, pages 2672‚Äì2680, 2014. 7\n",
      "[25] J. B. Hamrick, R. Pascanu, O. Vinyals, A. Ballard, N. Heess,\n",
      "and P. Battaglia. Imagination-based decision making with\n",
      "physical models in deep neural networks. 4\n",
      "[26] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE Con-\n",
      "\n",
      "\f",
      "[27]\n",
      "\n",
      "[28]\n",
      "\n",
      "[29]\n",
      "\n",
      "[30]\n",
      "[31]\n",
      "\n",
      "[32]\n",
      "\n",
      "[33]\n",
      "\n",
      "[34]\n",
      "\n",
      "[35]\n",
      "\n",
      "[36]\n",
      "[37]\n",
      "\n",
      "[38]\n",
      "\n",
      "[39]\n",
      "\n",
      "[40]\n",
      "\n",
      "[41]\n",
      "\n",
      "[42]\n",
      "\n",
      "ference on Computer Vision and Pattern Recognition, pages\n",
      "770‚Äì778, 2016. 1, 3, 7\n",
      "Y. Jiang, J. Liu, A. R. Zamir, G. Toderici, I. Laptev, M. Shah,\n",
      "and R. Sukthankar. Thumos challenge: Action recognition\n",
      "with a large number of classes, 2014. 2\n",
      "J. Johnson, B. Hariharan, L. van der Maaten, L. Fei-Fei,\n",
      "C. L. Zitnick, and R. Girshick. Clevr: A diagnostic dataset\n",
      "for compositional language and elementary visual reasoning.\n",
      "arXiv preprint arXiv:1612.06890, 2016. 2, 3\n",
      "P. J. Kellman and E. S. Spelke. Perception of partly occluded\n",
      "objects in infancy. Cognitive psychology, 15(4):483‚Äì524,\n",
      "1983. 1\n",
      "D. P. Kingma and J. Ba. Adam: A method for stochastic\n",
      "optimization. CoRR, abs/1412.6980, 2014. 12\n",
      "R. Krishna, Y. Zhu, O. Groth, J. Johnson, K. Hata, J. Kravitz,\n",
      "S. Chen, Y. Kalantidis, L.-J. Li, D. A. Shamma, et al. Visual genome: Connecting language and vision using crowdsourced dense image annotations. International Journal of\n",
      "Computer Vision, 123(1):32‚Äì73, 2017. 3\n",
      "M. Kristan, A. Leonardis, J. Matas, M. Felsberg,\n",
      "R. Pflugfelder, L. CÃåehovin, T. Vojir, G. HaÃàger, A. LukezÃåicÃå,\n",
      "and G. Fernandez. The visual object tracking vot2016 challenge results. Springer, Oct 2016. 3\n",
      "A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet\n",
      "classification with deep convolutional neural networks. In\n",
      "F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger,\n",
      "editors, Advances in Neural Information Processing Systems\n",
      "25, pages 1097‚Äì1105. Curran Associates, Inc., 2012. 1, 3\n",
      "L. Leal-TaixeÃÅ, A. Milan, I. Reid, S. Roth, and K. Schindler.\n",
      "MOTChallenge 2015: Towards a benchmark for multitarget tracking. arXiv:1504.01942 [cs], Apr. 2015. arXiv:\n",
      "1504.01942. 3\n",
      "A. Lerer, S. Gross, and R. Fergus. Learning physical intuition of block towers by example. International Conference\n",
      "on Machine Learning (ICML), 2016.\n",
      "\n",
      "IntPhys: A Framework and Benchmark for Visual Intuitive Physics Reasoning\n",
      "Ronan Riochet\n",
      "Ecole Normale Superieure\n",
      "INRIA\n",
      "\n",
      "Mario Ynocente Castro\n",
      "ycmario@gmail.com\n",
      "\n",
      "arXiv:1803.07\n",
      "\n",
      "üî¢ ÌÜ†ÌÅ∞ Ïàò (ÏïïÏ∂ï Ï†Ñ): 5665\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üìå [ÏïïÏ∂ï ÌõÑ Î¨∏Îß•]\n",
      "1. Introduction\n",
      "Despite impressive progress in machine vision on many\n",
      "tasks (face recognition [68], object recognition [33], [26],\n",
      "object segmentation [52], etc.), artificial systems are still far\n",
      "from human-level understanding of complex scenes. Scene\n",
      "understanding involves not only segmenting and tracking\n",
      "of objects across time, but also representing the spatial and\n",
      "temporal relationships between these objects and being able\n",
      "1\n",
      "\n",
      "\f",
      "Supplementary Material\n",
      " Framework details\n",
      "2 Rel work\n",
      "Most of the for intuitive\n",
      "has been conducted in the context particular end-to-endapplications. distinguish three broad classes depending on the type of data they use. The first\n",
      "includes tasks the vision- interface, where a\n",
      "model‚Äôs ability to reason about an image is assessed through\n",
      "a language task (e.g. generating a caption or answering a\n",
      "question about the image). The second class includes tasks\n",
      "which only use images or videos as input, such as predicting events in a video or tracking objects through time.\n",
      "The third class involves vision-action interface, with applications in robotics. that case systems require reasoning to control actions and predict their outcome.\n",
      "\n",
      "arXiv1803.7616v1 [cs.AI] 20 Mar 2018\n",
      "Adam\n",
      "Facebook AI Research\n",
      "Rob Fergus\n",
      "Facebook AI Research\n",
      "\n",
      "9. D\n",
      "See ,45 for‚Äô architect,Figure 6 samples semantic mask.\n",
      " https://github./\n",
      "rIntPhys-Baselines\n",
      "Abstract\n",
      "\n",
      "] Rhang, J, C Z, W. T, J. B. Tenenbaum A compar evaluation of simulation neural networks accounts human. CS,1.75]. Litnick and D. Parikh. Bring semanticsceedings of Conferenceisionognition30936, 03. \n",
      "\n",
      ". TrainingIntPhys: andchmark Visual Intuitive Physics\n",
      "on Riochcoleure\n",
      "INA\n",
      "an.et@.fr\n",
      "\n",
      "[10] G. Brockman, V. Cheung, L. Pettersson, J. Schneider,\n",
      "J. Schulman, J. Tang, and W. Zaremba. Openai gym. CoRR,\n",
      "abs/1606.01540, 2016. 2\n",
      "[11] S. Carey. The origin of concepts. Oxford series in cognitive\n",
      "development. Oxford University Press, Oxford ; New York,\n",
      "2009.\n",
      "\n",
      "üî¢ ÌÜ†ÌÅ∞ Ïàò (ÏïïÏ∂ï ÌõÑ): 554\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ÏïïÏ∂ï Ï†Ñ ÏõêÎ≥∏ Î¨∏Îß• Ï∂úÎ†•\n",
    "original_contexts = \"\\n\\n\".join([chunk.get_content() for chunk in retrieved_context])\n",
    "original_tokens = postprocessor._llm_lingua.get_token_length(original_contexts)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìå [ÏïïÏ∂ï Ï†Ñ Î¨∏Îß•]\")\n",
    "print(original_contexts[:3000])  # ÎÑàÎ¨¥ Í∏∏Î©¥ Ïïû Î∂ÄÎ∂ÑÎßå ÎØ∏Î¶¨ ÌôïÏù∏\n",
    "print(f\"\\nüî¢ ÌÜ†ÌÅ∞ Ïàò (ÏïïÏ∂ï Ï†Ñ): {original_tokens}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ÏïïÏ∂ï ÌõÑ Î¨∏Îß• Ï∂úÎ†•\n",
    "compressed_contexts = \"\\n\\n\".join([chunk.get_content() for chunk in new_retrieved_context])\n",
    "compressed_tokens = postprocessor._llm_lingua.get_token_length(compressed_contexts)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìå [ÏïïÏ∂ï ÌõÑ Î¨∏Îß•]\")\n",
    "print(compressed_contexts[:3000])  # ÎßàÏ∞¨Í∞ÄÏßÄÎ°ú ÏïûÎ∂ÄÎ∂ÑÎßå Ï∂úÎ†•\n",
    "print(f\"\\nüî¢ ÌÜ†ÌÅ∞ Ïàò (ÏïïÏ∂ï ÌõÑ): {compressed_tokens}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d8504-2ca6-49a5-816b-ca461253a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í∞Å Î¨∏ÏÑúÏóê ÎåÄÌï¥ ÎèÖÎ¶ΩÏ†ÅÏù∏ Ïã§ÌóòÏùÑ ÏßÑÌñâ\n",
    "for document_index in random_iterations:\n",
    "    # Í≤ÄÏÉâÏùÑ ÏúÑÌï¥ Í¥ÄÎ†® Î¨∏ÏÑúÎßå Ï∞∏Ï°∞ÌïòÍ≥† Ïù¥Î•º Î≤°ÌÑ∞ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Î°ú Ï≤òÎ¶¨:\n",
    "    index = VectorStoreIndex.from_documents(articles[document_index:(document_index + 1)])\n",
    "    print(\"\\n\\n                                                 Î¨∏ÏÑú Ïù∏Îç±Ïä§:\", document_index)\n",
    "    print(\"                                                 Î∞òÎ≥µ ÌöüÏàò:\", iteration_counter, \"/\", num_of_iterations)\n",
    "    iteration_counter += 1\n",
    "\n",
    "    # RAG Í≤ÄÏÉâ: Ïù¥ Î∂ÄÎ∂ÑÏùÄ ÎπÑÏïïÏ∂ï Î∞è ÏïïÏ∂ï Î∞©Ïãù Î™®ÎëêÏóêÏÑú Í≥µÌÜµ:\n",
    "    retrieval_start_time = time.time()\n",
    "    # Î≤°ÌÑ∞ DBÏóêÏÑú top_k Ï≤≠ÌÅ¨ Í≤ÄÏÉâ:\n",
    "    retriever = index.as_retriever(similarity_top_k=similarity_top_k)\n",
    "    retrieved_context = retriever.retrieve(query)\n",
    "    context_list = [chunk.get_content() for chunk in retrieved_context]\n",
    "    retrieval_time = time.time() - retrieval_start_time\n",
    "\n",
    "    # ÎπÑÏïïÏ∂ï RAG Î∞©Ïãù:\n",
    "    # ÏïïÏ∂ï ÏóÜÏù¥ LLMÏóê ÌîÑÎ°¨ÌîÑÌä∏Î•º Ï†ÑÎã¨ÌïòÎ©∞, ÏøºÎ¶¨Ïóê Í≤ÄÏÉâÎêú Î¨∏Îß• Ï≤≠ÌÅ¨Î•º Ï∂îÍ∞Ä:\n",
    "    start_time_nc = time.time()\n",
    "    prompt = \"\\n\\n\".join(context_list + [query])\n",
    "    response_nc = llm.complete(prompt)\n",
    "    time_nc = time.time() - start_time_nc\n",
    "    print(\"------------------------------------------------ ÎπÑÏïïÏ∂ï Î∞©Ïãù ÏùëÎãµ: \" + str(response_nc))\n",
    "\n",
    "    original_contexts = \"\\n\\n\".join(context_list)\n",
    "    original_tokens = postprocessor._llm_lingua.get_token_length(original_contexts)\n",
    "\n",
    "    # Ïù¥ ÏãúÏ†êÏóêÏÑú GPU Î©îÎ™®Î¶¨Î•º Ï†ïÎ¶¨ÌïòÎäî Í≤ÉÏù¥ ÌïÑÏöîÌï©ÎãàÎã§:\n",
    "    del prompt\n",
    "    del context_list\n",
    "    del original_contexts\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # ÏïïÏ∂ï Î¨∏Îß• RAG Î∞©Ïãù:\n",
    "    # ÏïïÏ∂ïÎêú Î¨∏Îß•ÏúºÎ°ú LLMÏóê ÌîÑÎ°¨ÌîÑÌä∏ Ï†ÑÎã¨:\n",
    "    start_time_c = time.time()\n",
    "    new_retrieved_context = postprocessor.postprocess_nodes(\n",
    "        retrieved_context,\n",
    "        query_bundle=QueryBundle(query_str=query)\n",
    "    )\n",
    "\n",
    "    response_c = CompactAndRefine().synthesize(query, new_retrieved_context)\n",
    "\n",
    "    time_c = time.time() - start_time_c\n",
    "\n",
    "    print(\"------------------------------------------------ ÏïïÏ∂ï Î∞©Ïãù ÏùëÎãµ: \" + str(response_c))\n",
    "\n",
    "    compressed_contexts = \"\\n\\n\".join([chunk.get_content() for chunk in new_retrieved_context])\n",
    "\n",
    "    compressed_tokens = postprocessor._llm_lingua.get_token_length(compressed_contexts)\n",
    "    ratio = original_tokens / (compressed_tokens + 1)\n",
    "\n",
    "    print(\"ÏõêÎûò ÌÜ†ÌÅ∞ Ïàò:\", original_tokens)\n",
    "    print(\"ÏïïÏ∂ïÎêú ÌÜ†ÌÅ∞ Ïàò:\", compressed_tokens)\n",
    "    print(\"ÏïïÏ∂ï ÎπÑÏú®:\", f\"{ratio:.2f}Î∞∞\")\n",
    "\n",
    "    record[str(response_nc).replace(\".\", \"\") + \",\" + str(response_c).replace(\".\", \"\")] += 1\n",
    "    record[\"original_tokens\"].append(original_tokens)\n",
    "    record[\"compressed_tokens\"].append(compressed_tokens)\n",
    "    record[\"ratios\"].append(ratio)\n",
    "    record[\"time_nc\"].append(time_nc + retrieval_time)\n",
    "    record[\"time_c\"].append(time_c + retrieval_time)\n",
    "\n",
    "    # GPUÏùò Î∂àÌïÑÏöîÌïú Ï∫êÏãú Í≥µÍ∞ÑÏùÑ Ï†ïÎ¶¨ÌïòÎäî Í≤ÉÏùÄ Ï¢ãÏùÄ ÏäµÍ¥ÄÏûÖÎãàÎã§:\n",
    "    del compressed_contexts\n",
    "    del new_retrieved_context\n",
    "    del retrieved_context\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c60914-3a66-4c34-ba22-2a395ee68781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0426f5-118a-4025-abc2-402c5b5afead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8901841d-73e1-4ca8-ac0c-853cf0c98843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
